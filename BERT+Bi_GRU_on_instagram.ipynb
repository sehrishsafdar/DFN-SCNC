{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZEOqD1MtQ1z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/instagram dataset_comments.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def tokenize_text(text):\n",
        "\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "    return tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors='tf')\n",
        "\n",
        "df['tokenized_comments'] = df['comments'].apply(tokenize_text)\n",
        "df['tokenized_statements'] = df['statements'].apply(tokenize_text)\n"
      ],
      "metadata": {
        "id": "s55lGMRZtXlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Bidirectional, GRU, Dense, Concatenate\n",
        "from transformers import TFBertModel, BertTokenizer\n",
        "import transformers"
      ],
      "metadata": {
        "id": "-dkkk6U2tfVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_comments = Input(shape=(128,), dtype=tf.int32, name='input_ids_comments')\n",
        "input_mask_comments = Input(shape=(128,), dtype=tf.int32, name='attention_mask_comments')\n",
        "input_ids_statements = Input(shape=(128,), dtype=tf.int32, name='input_ids_statements')\n",
        "input_mask_statements = Input(shape=(128,), dtype=tf.int32, name='attention_mask_statements')"
      ],
      "metadata": {
        "id": "ZHaHTvmDufq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = transformers.TFBertModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "EOnXUmWnujKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_layer_comments = tf.keras.layers.Lambda(lambda x: bert_model(x[0], attention_mask=x[1])[0])([input_ids_comments, input_mask_comments])\n",
        "bert_layer_statements = tf.keras.layers.Lambda(lambda x: bert_model(x[0], attention_mask=x[1])[0])([input_ids_statements, input_mask_statements])"
      ],
      "metadata": {
        "id": "cRPThBrlumI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_output_comments = Bidirectional(GRU(64))(bert_layer_comments)\n",
        "gru_output_statements = Bidirectional(GRU(64))(bert_layer_statements)"
      ],
      "metadata": {
        "id": "LvVmT3KRup-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concatenated_output = Concatenate()([gru_output_comments, gru_output_statements])"
      ],
      "metadata": {
        "id": "-clD1TR3utMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "output = Dense(6, activation='softmax')(concatenated_output)"
      ],
      "metadata": {
        "id": "KoMZyClfuy_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input_ids_comments, input_mask_comments, input_ids_statements, input_mask_statements], outputs=output)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "GEtqXwIxu1_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_comments_ids = tf.squeeze(tf.stack([x['input_ids'] for x in X_train_comments]))\n",
        "X_train_comments_masks = tf.squeeze(tf.stack([x['attention_mask'] for x in X_train_comments]))\n",
        "X_train_statements_ids = tf.squeeze(tf.stack([x['input_ids'] for x in X_train_statements]))\n",
        "X_train_statements_masks = tf.squeeze(tf.stack([x['attention_mask'] for x in X_train_statements]))"
      ],
      "metadata": {
        "id": "ytV0Z5shu47l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test_comments_ids = tf.squeeze(tf.stack([x['input_ids'] for x in X_test_comments]))\n",
        "X_test_comments_masks = tf.squeeze(tf.stack([x['attention_mask'] for x in X_test_comments]))\n",
        "X_test_statements_ids = tf.squeeze(tf.stack([x['input_ids'] for x in X_test_statements]))\n",
        "X_test_statements_masks = tf.squeeze(tf.stack([x['attention_mask'] for x in X_test_statements]))"
      ],
      "metadata": {
        "id": "H6eCVETLu9DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit(\n",
        "    [X_train_comments_ids, X_train_comments_masks, X_train_statements_ids, X_train_statements_masks],\n",
        "    y_train,\n",
        "    validation_data=([X_test_comments_ids, X_test_comments_masks, X_test_statements_ids, X_test_statements_masks], y_test),\n",
        "    epochs=1,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "4naaSaq8vDJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate([X_test_comments_ids, X_test_comments_masks, X_test_statements_ids, X_test_statements_masks], y_test)\n",
        "print(\"Test Loss, Test Accuracy:\", results)"
      ],
      "metadata": {
        "id": "jGNhPrqAvHEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict([X_test_comments_ids, X_test_comments_masks, X_test_statements_ids, X_test_statements_masks])\n",
        "y_pred_labels = y_pred.argmax(axis=1)\n",
        "y_true_labels = y_test.values.argmax(axis=1)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true_labels, y_pred_labels))\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
        "precision = precision_score(y_true_labels, y_pred_labels, average='weighted')\n",
        "recall = recall_score(y_true_labels, y_pred_labels, average='weighted')\n",
        "f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "OHqh_33vuCx4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}